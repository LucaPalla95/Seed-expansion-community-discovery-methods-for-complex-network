{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e4634-7ae5-412c-a7b4-a6d63eef7866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from graph_tool.all import * \n",
    "import numpy as np\n",
    "import random as rdm\n",
    "from itertools import islice\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c518a7-f081-48c4-aac0-17d5175ca2d0",
   "metadata": {},
   "source": [
    "## MISURE E METRICHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9968c7f-210b-4133-9b10-78590d9110af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Internal community cohesion\n",
    "def Internal_community_cohesion(Graph, Local_Community, candidate_node=None):\n",
    "    #Mi prendo i nodi della comunità locale (set) (Sorted perchè utilizzo lista)\n",
    "    Loc_C = Local_Community.copy()\n",
    "    #Adesso controllo che la mia local community non abbia come unico vicino il nodo candidato. Se è così gli attribuisco massima importanza. Esempio unico nodo connesso ad hub.\n",
    "    neigh_loc = set()\n",
    "    for node in Loc_C:\n",
    "        # Prendo i vicini della community locale\n",
    "        neigh_loc.update(Graph.vertex(node).out_neighbors())\n",
    "\n",
    "    if candidate_node != None:\n",
    "        if len(list(neigh_loc)) == 1:\n",
    "            if list(neigh_loc)[0] == candidate_node:\n",
    "                return 10\n",
    "        Loc_C.append(candidate_node)\n",
    "    #Inizializzo internal tightness\n",
    "    ITC = 0\n",
    "    lenght = len(Loc_C)\n",
    "    Loc_C = list(Loc_C)\n",
    "    #Per ogni core node e candidato nuovo vertice, calcolo la ITC\n",
    "    for node in range(lenght):\n",
    "        core_node = Loc_C[node]\n",
    "        neighb = Graph.get_out_neighbors(core_node)\n",
    "        neighbs = set(neighb).intersection(set(Loc_C))\n",
    "        for negh in neighbs:\n",
    "            if core_node < negh:\n",
    "                ITC += ILW(Graph, core_node, negh)\n",
    "                \n",
    "    if ITC == 0 or ITC == None:\n",
    "        return 0\n",
    "    else:\n",
    "        return ITC[0]\n",
    "\n",
    "\n",
    "\n",
    "#External community cohesion\n",
    "def External_community_cohesion(Graph, Local_Community, candidate_node=None):\n",
    "    #Mi prendo i nodi della comunità locale (set) (Sorted perchè utilizzo lista)\n",
    "    Loc_C = Local_Community.copy()\n",
    "    if candidate_node != None:\n",
    "        Loc_C.append(candidate_node)\n",
    "    #aggiungo alla comunità anche il nodo candidato\n",
    "    core_vertices_exp = sorted(Loc_C)\n",
    "    #definisco cos'è un boundary node: Tutti i nodi nella community che hanno almeno un vicino in U (vedere paper)\n",
    "    boundary_node = set()\n",
    "    for node in core_vertices_exp:\n",
    "        neigh = set()\n",
    "        # Prendo i vicini della community locale\n",
    "        neigh.update(Graph.vertex(node).out_neighbors())\n",
    "        if neigh.difference(Loc_C):\n",
    "            boundary_node.add(node)\n",
    "    #Inizializzo external tightness\n",
    "    ETC = 0\n",
    "    #Per ogni boundary node e candidato nuovo vertice calcolo la ETC\n",
    "    for bound_node in boundary_node:\n",
    "        neighb = Graph.vertex(bound_node).out_neighbors()\n",
    "        neigh_not_core_vertices_exp = set(neighb).difference(set(core_vertices_exp))\n",
    "        for neighbb in neigh_not_core_vertices_exp:\n",
    "            ETC += ILW(Graph, bound_node, neighbb)\n",
    "    \n",
    "    if ETC == 0 or ETC == None:\n",
    "        return 1\n",
    "    else:\n",
    "        return ETC[0]\n",
    "\n",
    "\n",
    "# Community Cohesion\n",
    "def Community_Cohesion(Graph, Local_Community, candidate_node=None):\n",
    "    ITC = Internal_community_cohesion(Graph, Local_Community, candidate_node)\n",
    "    ETC = External_community_cohesion(Graph, Local_Community, candidate_node)\n",
    "    if ETC == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return ITC/ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb91871-5681-4d59-a192-d88692ed9dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jaccard\n",
    "def Jaccard(Graph,NodeU,NodeV):\n",
    "    jaccard = vertex_similarity(Graph, vertex_pairs=[(NodeU, NodeV)])\n",
    "    return jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe812095-2cd4-4285-87a2-41192099e2db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Jaccard_Temp(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64509db8-a723-4726-81d4-19f994866f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inv-log-weight\n",
    "def ILW(Graph,NodeU,NodeV):\n",
    "    jaccard = vertex_similarity(Graph, vertex_pairs=[(NodeU, NodeV)], sim_type='inv-log-weight')\n",
    "    return jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5934da-76f5-4d19-bbf2-a44931fae4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conductance\n",
    "def compute_conductance(graph, community):\n",
    "    cut_vertices = community\n",
    "    # Calculate the conductance given a set of cut vertices\n",
    "    boundary_edges = []\n",
    "    total_weight = 0\n",
    "    cut_weight = 0\n",
    "\n",
    "    for v in cut_vertices:\n",
    "        for e in graph.iter_all_edges(v):\n",
    "            #Conto +1 per ogni link per calcolare Vol(S)\n",
    "            total_weight += 1\n",
    "            #Link che inizio o finisco in S, ma non entrambi\n",
    "            if graph.vertex_index[e[0]] not in cut_vertices or graph.vertex_index[e[1]] not in cut_vertices:\n",
    "                boundary_edges.append(e)\n",
    "                cut_weight += 1\n",
    "\n",
    "    den = min( total_weight , 2 *len(list(graph.edges()))- total_weight)\n",
    "    if den > 0:\n",
    "        conductance = cut_weight / den\n",
    "    else:\n",
    "        conductance = 0\n",
    "    #print('cut_weight' , cut_weight, 'total_weight', total_weight, 'total_weight_compl', len(list(graph.edges()))- total_weight)\n",
    "    return conductance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947b3f6e-0920-40ba-adcf-7679f4357c89",
   "metadata": {},
   "source": [
    "## Algoritmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8cc810-1651-45ce-be35-4c65f35fcb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search Friends\n",
    "def take(n, iterable):\n",
    "    \"\"\"Return the first n items of the iterable as a list.\"\"\"\n",
    "    return islice(iterable, n)\n",
    "\n",
    "def search_friends(g, LC, max_d): \n",
    "    ego_net = set()\n",
    "    #creo nuova vp utile per definire successivamente il subgraph dell'ego_net\n",
    "    vfiltered = g.new_vertex_property('bool')\n",
    "    #creo un dizionario per i nodi utile a racchiuderne il degree interno e quello totale\n",
    "    node_dict = dict()\n",
    "    for node in LC:\n",
    "        vert_prop, tuple = shortest_distance(g, node, max_dist=max_d, return_reached=True) \n",
    "        #aggiungo i nodi che trovo a distanza 1 per ogni songolo nodo nella local community\n",
    "        ego_net = ego_net.union(set(tuple))\n",
    "    #attribuisco la vertex property necessaria a creare il subgraph\n",
    "    vfiltered.a[list(ego_net)] = True\n",
    "    vfiltered.a[list(LC)] = True\n",
    "    graph_filtered = GraphView(g, vfiltered) \n",
    "    #creo due vertex property in modo tale da calcolarmi il total degree dei nodi sia dentro il netwrok intero che nell'ego\n",
    "    vpp_d_full = g.degree_property_map('total')\n",
    "    vpp_d_ego = graph_filtered.degree_property_map('total')\n",
    "    ego_not_in_LC = ego_net.difference(set(LC))\n",
    "    for node in ego_not_in_LC:\n",
    "        #Mi vado a calcolare il rapporto fra il degree interno all'ego e quello totale del network\n",
    "        tot_degree = vpp_d_full[node]\n",
    "        tot_degree_ego = vpp_d_ego[node]\n",
    "        #definisco tale misura come friendship\n",
    "        friendship = tot_degree_ego/tot_degree\n",
    "        #Aggiungo il nodo con la friendship al dizionario dei nodi\n",
    "        node_dict[node] = friendship\n",
    "    #Ordino il dizionario in ordine decrescente in base alla friendship e poi vado a prendere i primi dieci elementi\n",
    "    sorted_dict = sorted(node_dict.items(), key = lambda x: x[1], reverse=True)\n",
    "    nodes = take(10, sorted_dict)\n",
    "\n",
    "    \n",
    "    return list(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407e302d-efa4-4a1a-a07b-394466641bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search Friends per espansione secondaria\n",
    "def ExpandFriends(g, LC, max_d): \n",
    "    ego_net = set()\n",
    "    #creo nuova vp utile per definire successivamente il subgraph dell'ego_net\n",
    "    vfiltered = g.new_vertex_property('bool')\n",
    "    vfiltered_ego_no_lc = g.new_vertex_property('bool')\n",
    "    #creo un dizionario per i nodi utile a racchiuderne il degree interno e quello totale\n",
    "    node_dict = dict()\n",
    "    for node in LC:\n",
    "        vert_prop, tuple = shortest_distance(g, node, max_dist=max_d, return_reached=True) \n",
    "        #aggiungo i nodi che trovo a distanza 1 per ogni songolo nodo nella local community\n",
    "        ego_net = ego_net.union(set(tuple))\n",
    "        \n",
    "    #attribuisco la vertex property necessaria a creare il subgraph\n",
    "    vfiltered.a[list(ego_net)] = True\n",
    "    vfiltered.a[list(LC)] = True\n",
    "    graph_filtered = GraphView(g, vfiltered) \n",
    "    #creo un subgraph con solo i nodi che fanno parte dell'ego ma non della LC per poi calcolarmi anche la lite_friendship. \n",
    "    ego_not_in_LC = ego_net.difference(set(LC))\n",
    "    vfiltered_ego_no_lc.a[list(ego_not_in_LC)] = True\n",
    "    graph_filtered_ego_no_lc = GraphView(g, vfiltered_ego_no_lc)\n",
    "    #clacolo i vari degree totali\n",
    "    vpp_d_full = g.degree_property_map('total')\n",
    "    vpp_d_ego = graph_filtered.degree_property_map('total')\n",
    "    vpp_d_ego_no_lc = graph_filtered_ego_no_lc.degree_property_map('total')\n",
    "    for node in ego_not_in_LC:\n",
    "        #Mi vado a calcolare il rapporto fra il degree interno all'ego e quello totale del network\n",
    "        tot_degree = vpp_d_full[node]\n",
    "        tot_degree_ego = vpp_d_ego[node]\n",
    "        tot_degree_ego_no_lc = vpp_d_ego_no_lc[node] #questo valore mi dice il # di connessioni dei nodi nell'ego escludendo la LC.\n",
    "        #definisco tale misura come friendship\n",
    "        friendship = tot_degree_ego/tot_degree\n",
    "        lite_friendship = tot_degree_ego_no_lc/tot_degree_ego\n",
    "        #print(node, friendship, lite_friendship)\n",
    "        #Aggiungo il nodo con la friendship al dizionario dei nodi\n",
    "        node_dict[node] = [friendship, lite_friendship]\n",
    "    \n",
    "    return node_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d26d11e-7a0d-4cf7-8c0c-8b147ecc8d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CoreAreaDetection(Graph, seed_node, subgraphs = False, failure_node = None):\n",
    "    if failure_node is None:\n",
    "        failure_node = set()\n",
    "    LC = set()\n",
    "    LC.add(seed_node)\n",
    "    #Inizializzo CT a 0\n",
    "    Comm_cohesion = 0\n",
    "    Comm_cohesion_pre = -1\n",
    "    V = list(Graph.iter_vertices())\n",
    "    while Comm_cohesion > Comm_cohesion_pre:\n",
    "        #Al posto di cercare tutti i neighboors utilizzo funzione per cercare solo i top 10 per friendship\n",
    "        neigh_comm = search_friends(Graph, LC, 1)\n",
    "        if len(neigh_comm) == 0:\n",
    "            vcommunity = Graph.new_vp(\"int32_t\")\n",
    "            for node in LC:\n",
    "                vcommunity[Graph.vertex(node)] = 1\n",
    "            return LC, 0, vcommunity, failure_node\n",
    "        Candidates = []\n",
    "        #per ogni top 10 (prendo [0] perchè la funzione mi ritorna una tuple con anche la misura di friendship) la Node CT che altro non è che il Delta nella CT causato dall'aggiunta di quel nodo alla LC\n",
    "        #print('neigh_comm',neigh_comm[0])\n",
    "        for node, _ in neigh_comm:\n",
    "            #print('node', node)\n",
    "            community_coe = Community_Cohesion(Graph, list(LC), node)\n",
    "            difference_CT_NCT = community_coe-Comm_cohesion\n",
    "            #print('difference_CT_NCT', difference_CT_NCT)\n",
    "            #Se il Delta è positivo aggiungo il nodo ai candidati\n",
    "            if difference_CT_NCT > 0:\n",
    "                Candidates.append([node, difference_CT_NCT])\n",
    "                #print('node', node, 'diff_CT', difference_CT_NCT, 'NCT', community_coe)\n",
    "        #print('Candidates', Candidates)\n",
    "        # Faccio distinzione dal fatto che ho solo il seed o anche altri nodi\n",
    "        Candidates.sort(key=lambda x: x[1], reverse = True)\n",
    "        for node, _ in Candidates:\n",
    "            LC.add(int(node))\n",
    "            #print('LC dopo add', LC)\n",
    "            break\n",
    "        #se non riesco a catturare nodi nella prima run della LC perchè ad esempio è ponte o è vertice esterno, allora aggiungo come tentivo il vicino che\n",
    "        # ha la connessione più forte in termini di tot_d_ego/tot_d e metto a 0.0001 la CT\n",
    "        while len(LC) == 1:\n",
    "            if seed_node in failure_node:\n",
    "                LC = LC.union(failure_node)\n",
    "                break\n",
    "            else:\n",
    "                failure_node.add(seed_node)\n",
    "                LC, Comm_cohesion, _, failure_node = CoreAreaDetection(Graph, int(neigh_comm[0][0]), failure_node = failure_node)\n",
    "        LC = LC.union(failure_node)\n",
    "        #print('best_candidates', best_candidates)\n",
    "        # Da Vedere come calcolare per via del fatto che il candidate node ora qua non c'è.\n",
    "        Comm_cohesion_pre = Comm_cohesion\n",
    "        #print('pre_ct',Comm_cohesion)\n",
    "        Comm_cohesion = Community_Tightness(Graph, LC)\n",
    "        #print('post_ct',Comm_cohesion)\n",
    "    \n",
    "    vcommunity = Graph.new_vp(\"int32_t\")\n",
    "    for node in LC:\n",
    "        vcommunity[Graph.vertex(node)] = 1\n",
    "    if subgraphs == True:\n",
    "        sub = GraphView(Graph, vfilt=vcommunity.a == 1)\n",
    "        graph_draw(sub, vprop=Jaccard, vertex_text=sub.vertex_index)\n",
    "    return LC, Comm_cohesion, vcommunity, failure_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48467d3-c6ae-4789-b877-b46c583ebf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CoreAreaExtension(Graph, LC, p_lambda = 0.6, subgraphs = False):\n",
    "\n",
    "    Conductance = compute_conductance(Graph, LC)\n",
    "    Conductance_pre = 1\n",
    "    LC_pre = {}\n",
    "    #contatore per tenere conto se vi sono nodi aggiunti all'iniziale LC\n",
    "    while Conductance_pre > Conductance:\n",
    "        LC_pre = LC.copy()\n",
    "        #Vado a ricreare un ego_network considerando l'intera area iniziale (LC)\n",
    "        nodi_booster = search_friends_final(Graph, LC, 1)\n",
    "        i = 0\n",
    "        #print(i)\n",
    "        for k,v in nodi_booster.items():\n",
    "            #v[0] è tot_d_ego/tot_d mentre\n",
    "            if v[0] > p_lambda and v[1] < v [0]: #la logica è che devo avere più connessioni nell'ego, ma queste devono essere maggiormente con la LC che crea l'ego\n",
    "                LC.add(int(k))\n",
    "                i +=1\n",
    "        #print(LC)\n",
    "        #Se ho aggiunto almeno un nodo vado a cercare per uno step altri eventuali nodi isolati\n",
    "        if i > 0:\n",
    "            new_nodi_booster = search_friends_final(Graph, LC, 1)\n",
    "            for k,v in new_nodi_booster.items():\n",
    "                #v[1] è tot_d_ego_no_lc/tot_d\n",
    "                if (v[0] == 1 and v[1] == 0): #la logica qua implicata è che aggiungo i nodi che sono solo connessi con la community espansa e che sennò risulterebbero isolati\n",
    "                    LC.add(int(k))\n",
    "            Conductance_pre = Conductance\n",
    "            Conductance = compute_conductance(Graph, LC)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    Comm_cohesion = Community_Cohesion(Graph, LC_pre)\n",
    "\n",
    "    vcommunity = Graph.new_vp(\"int32_t\")\n",
    "    for node in LC_pre:\n",
    "        vcommunity[Graph.vertex(node)] = 1\n",
    "    if subgraphs == True:\n",
    "        sub = GraphView(Graph, vfilt=vcommunity.a == 1)\n",
    "        graph_draw(sub, vprop=Jaccard, vertex_text=sub.vertex_index)\n",
    "    \n",
    "    return LC_pre, Comm_cohesion, vcommunity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0458e251-7cee-4523-9e4c-6df49c4df846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LECD(Graph, seed, p_lambda = 0.6, subgraph_core_area = False, subgraph_LC = False):\n",
    "    LC, _x, _y, _z = CoreAreaDetection(Graph, seed, subgraph_core_area)\n",
    "    LC_finale, CT, vpp = CoreAreaExtension(Graph, LC, p_lambda, subgraph_LC)\n",
    "    return LC_finale, CT, vpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568cb22d-02e4-4d87-8659-58f557fc6c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Partition_Extraction(Graph, seed):\n",
    "    G = Graph\n",
    "    #lista dei nodi all'interno del grafo\n",
    "    V = list(G.iter_vertices())\n",
    "    s = seed\n",
    "    #set dei nodi già usati\n",
    "    V_used = set()\n",
    "    # dizionario delle comunità\n",
    "    LC_Dict = {}\n",
    "    #Creo nuova vertex property\n",
    "    vcommunity = G.new_vp(\"int32_t\")\n",
    "    \n",
    "    #Guardo al grado di tutti i nodi per andare ad escludere quelli isolati\n",
    "    degree = G.get_total_degrees(V)\n",
    "    V_no_isolated = set(v for v, de in zip(V, degree) if de != 0)\n",
    "\n",
    "    #serve a nominare in via progressiva le comunitò\n",
    "    i=0\n",
    "    while len(V_no_isolated) != 0: \n",
    "        i+=1\n",
    "        Local_comm, CH, vpp, _ = CoreAreaDetection(G, s)\n",
    "        #vado a rimuovere i nodi che ho utilizzato nella comunità così che non li posso ripescare come seed\n",
    "        V_no_isolated -= Local_comm\n",
    "        #serve a vedere se un nodo già assegnato viene riasssegnato alla nuova comunità, se nessuno lo è si procede a crearne una nuova\n",
    "        if not Local_comm.intersection(V_used):\n",
    "            LC_Dict['LC_{}'.format(i)] = [Local_comm,  CH, compute_conductance(G, list(Local_comm))]\n",
    "            for node in Local_comm:\n",
    "                vcommunity[G.vertex(node)] = i\n",
    "        else:\n",
    "            # se qualche nodo già usato viene riutilizzato si va a calcolare con le altre comunità già esistenti la len(dell'intersezione)\n",
    "            # e si utilizza come parametro per capire a quale comunità unire quella nuova.\n",
    "            new_LC = Local_comm\n",
    "            comm_to_delete = []\n",
    "            for loc_comm, comm_stats in LC_Dict.items():\n",
    "                score = len(comm_stats[0].intersection(new_LC))\n",
    "                if score > 0:\n",
    "                    new_LC = new_LC.union(comm_stats[0])\n",
    "                    comm_to_delete.append(loc_comm)\n",
    "                \n",
    "            LC_Dict['LC_{}'.format(i)] = [new_LC, Community_Cohesion(G, new_LC), compute_conductance(G, list(new_LC))]\n",
    "            for comm_to_del in comm_to_delete:\n",
    "                del LC_Dict['{}'.format(comm_to_del)]\n",
    "            for node in new_LC:\n",
    "                vcommunity[G.vertex(node)] = i\n",
    "        #si aggiorna il set dei nodi già usati\n",
    "        V_used = V_used.union(Local_comm)\n",
    "        if len(V_no_isolated) != 0:\n",
    "            s = rdm.choice(list(V_no_isolated))\n",
    "    return LC_Dict, vcommunity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0100b075-b553-4930-a99f-b6e82ea06132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Partition_Optimization(Graph, LC_Dict):\n",
    "    LC_Dict_Copy = LC_Dict.copy()\n",
    "    while len(LC_Dict_Copy) >1:\n",
    "        #print('len_before', len(LC_Dict_Copy))\n",
    "        Max_delta_CND = 0\n",
    "        max_CND_LC = max(LC_Dict_Copy, key=lambda k: (LC_Dict_Copy[k][2], LC_Dict_Copy[k][1], LC_Dict_Copy[k]))\n",
    "        if LC_Dict_Copy[max_CND_LC][2] > 0.30:\n",
    "            Comm_under_evaluation = LC_Dict_Copy[max_CND_LC][0]\n",
    "            #print('community_ue', Comm_under_evaluation, 'max_CND_LC', max_CND_LC)\n",
    "            neigh_Comm_under_evaluation = set()\n",
    "            for node in Comm_under_evaluation:\n",
    "                neigh_Comm_under_evaluation.update(G.vertex(node).out_neighbors())\n",
    "                # for neigh in G.iter_all_neighbors(node):\n",
    "                    # neigh_Comm_under_evaluation.add(neigh)\n",
    "            new_community = set()\n",
    "            key_max =-100\n",
    "            for key, values in LC_Dict_Copy.items():\n",
    "                #print('comm_da comparare', values[0], 'LC', key)\n",
    "                if key == max_CND_LC:\n",
    "                    continue\n",
    "                else:\n",
    "                    if neigh_Comm_under_evaluation.intersection(values[0]):\n",
    "                        new_comm = Comm_under_evaluation.union(values[0])\n",
    "                        CH_new = Community_Cohesion(G, new_comm)\n",
    "                        Cnd_Comm_new = compute_conductance(G, list(new_comm))\n",
    "                        #print('CH_new', CH_new, 'Cnd_Comm_new', Cnd_Comm_new)\n",
    "                        Delta_CH = CH_new - values[1]\n",
    "                        Delta_CND = values[2] - Cnd_Comm_new\n",
    "                        # print('Delta_CH', Delta_CH, 'Delta_CND', Delta_CND)\n",
    "                        if Delta_CND >= Max_delta_CND and Delta_CH >= 0:\n",
    "                            key_max = key\n",
    "                            new_community = new_comm\n",
    "                            #print('new_community', new_community)\n",
    "                            Max_delta_CND = Delta_CND\n",
    "                            #print('Max_delta_CND', Max_delta_CND)\n",
    "            if new_community and new_community != Comm_under_evaluation:\n",
    "                #print('pre_LC_DICT', LC_Dict)\n",
    "                LC_Dict[key_max] = [new_community, Community_Cohesion(G, new_community), compute_conductance(G, list(new_community))]\n",
    "                #print(new_community, Community_Cohesion(G, new_community), compute_conductance(G, list(new_community))\n",
    "                del LC_Dict[max_CND_LC]\n",
    "                #print('post_LC_DICT', LC_Dict)\n",
    "                #print('pre_LC_DICT_copy', LC_Dict_Copy)\n",
    "                LC_Dict_Copy[key_max] = [new_community, Community_Cohesion(G, new_community), compute_conductance(G, list(new_community))]\n",
    "                del LC_Dict_Copy[max_CND_LC]\n",
    "                #print('post_LC_DICT_copy', LC_Dict_Copy)\n",
    "                for node in new_community:\n",
    "                    vcommunity[G.vertex(node)] = key_max[3:]\n",
    "            else:\n",
    "                del LC_Dict_Copy[max_CND_LC]\n",
    "        else:\n",
    "            break\n",
    "        #print('len_after', len(LC_Dict_Copy)) \n",
    "        #print('')\n",
    "        #print('')\n",
    "    return LC_Dict, vcommunity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1080950f-41e3-4194-9a2d-ab5131e0d252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GELSE(Graph, seed, opt=False):\n",
    "    LC_D, vpp = Partition_Extraction(Graph, seed)\n",
    "    if opt == True:\n",
    "        LCs_Opt, vpp = Partition_Optimization(Graph, LC_D)\n",
    "        return LCs_Opt\n",
    "    return LC_D, vpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131db9f3-75d2-4792-a4e7-b1a9b6a058a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TECD(list_g, seed, subgraphs = False, stats = False, evolution=False):\n",
    "    graphs = list_g\n",
    "    Dict_Temporal_communities = {}\n",
    "    List_Subgraph = []\n",
    "    list_vpp = []\n",
    "    count = 1\n",
    "    \n",
    "    for T_graph in graphs:\n",
    "        vcommunity = T_graph.new_vp(\"int32_t\")\n",
    "        #Local Community\n",
    "        LC, _, _ = LECD(T_graph, seed)\n",
    "        for node in LC:\n",
    "            vcommunity[T_graph.vertex(node)] = 1\n",
    "            list_vpp.append(vcommunity)\n",
    "        #Aggiungo lC al dizionario\n",
    "        Dict_Temporal_communities['tc_{}'.format(count)] = LC\n",
    "        count += 1\n",
    "\n",
    "        \n",
    "        if subgraphs == True:\n",
    "            sub = GraphView(T_graph, vfilt=vcommunity.a == 1)\n",
    "            List_Subgraph.append(sub)\n",
    "            \n",
    "    if evolution:\n",
    "        for i, comm in enumerate(List_Subgraph):\n",
    "            if i == 0:\n",
    "                vcolor = List_Subgraph[i].new_vp(\"string\")\n",
    "                nodes_removed = set(List_Subgraph[i].vertices()).difference(set(List_Subgraph[i+1].vertices()))\n",
    "                for node in List_Subgraph[i].vertices():\n",
    "                    if node in nodes_removed:\n",
    "                        vcolor[node] = 'red'\n",
    "                    else:\n",
    "                        vcolor[node] = 'yellow'\n",
    "                graph_draw(List_Subgraph[i], vprop=Jaccard, vertex_text=subgraph[i].vertex_index, vertex_fill_color=vcolor, output=\"SubGraph_T{}.png\".format(i))\n",
    "\n",
    "                \n",
    "            else:\n",
    "                nodes_added = set(list(Dict_Temporal_communities.values())[i]).difference(set(list(Dict_Temporal_communities.values())[i-1]))\n",
    "                if len(List_Subgraph) != i+1:\n",
    "                    nodes_removed = set(list(Dict_Temporal_communities.values())[i]).difference(set(list(Dict_Temporal_communities.values())[i+1]))\n",
    "                vcolor = List_Subgraph[i].new_vp(\"string\")\n",
    "                for node in List_Subgraph[i].vertices():\n",
    "                    if nodes_removed:\n",
    "                        if node in nodes_added.intersection(nodes_removed):\n",
    "                            vcolor[node] = 'purple'\n",
    "                        elif node in nodes_added:\n",
    "                            vcolor[node] = 'green'\n",
    "                        elif node in nodes_removed:\n",
    "                            vcolor[node] = 'red'\n",
    "                        else:\n",
    "                            vcolor[node] = 'yellow'\n",
    "                    else:\n",
    "                        if node in nodes_added:\n",
    "                            vcolor[node] = 'green'\n",
    "                        else:\n",
    "                            vcolor[node] = 'yellow'\n",
    "                graph_draw(List_Subgraph[i], vprop=Jaccard, vertex_text=List_Subgraph[i].vertex_index, vertex_fill_color=vcolor, output=\"SubGraph_T{}.png\".format(i))\n",
    "\n",
    "\n",
    "    if stats == True:\n",
    "        J = []\n",
    "        LCs = []\n",
    "        for k, v in Dict_Temporal_communities.items():\n",
    "            LCs.append(v)\n",
    "        i = 0\n",
    "        while i < len(LCs) -1:\n",
    "            Jac = jaccard_temp(LCs[i], LCs[i+1])\n",
    "            print('Jaccard between tc_{} and tc_{} is {}'.format(i, i+1, Jac))\n",
    "            print('Nodes that have left the community: {}'.format(set(LCs[i]).difference(set(LCs[i]).intersection(set(LCs[i+1])))))\n",
    "            print('Nodes that have remained in the community: {}'.format(set(LCs[i]).intersection(set(LCs[i+1]))))\n",
    "            print('Nodes that have joined the community: {}'.format(set(LCs[i+1]).difference(set(LCs[i]))))\n",
    "            print('')\n",
    "            i += 1\n",
    "    if subgraphs == True:\n",
    "        return Dict_Temporal_communities, list_vpp, List_Subgraph\n",
    "    else:\n",
    "        return Dict_Temporal_communities, list_vpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c66bda-ec60-459c-aecd-169039f73d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63b9064-747a-4851-8a7f-f804fc0a92a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
